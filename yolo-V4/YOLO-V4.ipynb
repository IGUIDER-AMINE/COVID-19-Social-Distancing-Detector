{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "26c3ce5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import sqrt\n",
    "def euclidienne(x1,y1, x2,y2):\n",
    "    d = sqrt((x1-x2)**2 + (y1-y2)**2)\n",
    "    return d\n",
    "def centre(x,y,w,h):\n",
    "    cx = x + (w-x)//2\n",
    "    cy = y + (h-y)//2\n",
    "    return (cx, cy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d6518d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9fe7ea88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saisir la distance: 40\n"
     ]
    }
   ],
   "source": [
    "#Chargez notre détecteur d'objets YOLO\n",
    "net = cv2.dnn.readNetFromDarknet('Yolo4/yolov4.cfg', 'Yolo4/yolov4.weights')\n",
    "ln = net.getLayerNames()\n",
    "ln = [ln[i - 1] for i in net.getUnconnectedOutLayers()]\n",
    "\n",
    "DEFAULT_CONFIANCE = 0.5 # la probabilité\n",
    "THRESHOLD = 0.4 #un seuil qui va permettre d'éliminer la mauvaise détection\n",
    "#Charger les étiquettes de classe COCO sur lesquelles notre modèle YOLO a été formé\n",
    "with open('Yolo4/coco.names', 'r') as f:\n",
    "    LABELS = f.read().splitlines()\n",
    "\n",
    "#Initialiser le flux vidéo, pointeur vers le fichier vidéo de sortie\n",
    "cap = cv2.VideoCapture(\"../vedios/people.mp4\")\n",
    "N = int(input(\"Saisir la distance: \"))\n",
    "while True:\n",
    "    _,image=cap.read()\n",
    "    # les coordonnées d'une image\n",
    "    height, width, _ = image.shape \n",
    "    #préparer image pour le traitement\n",
    "    #l'echelle :on va diviser chaque pixel par des 155\n",
    "    #taille d'image => (416, 416)\n",
    "    #swapRB=True    => converti des images qui sont passés par défaut en RGB\n",
    "    #crop=False     => on ne veut pas couper notre image \n",
    "    blob = cv2.dnn.blobFromImage(image, 1/255, (416, 416), (0,0,0), swapRB=True, crop=False)\n",
    "    net.setInput(blob)\n",
    "    layerOutputs = net.forward(ln)\n",
    "    \n",
    "    #Initialiser nos listes de boîtes englobantes, de confiances et d'ID de classe détectés, respectivement\n",
    "    boxes = [] #compter les différentes zones qui seront détectés son image\n",
    "    confidences = [] # le niveau de confiance pour chacune des zones qui a été détecté \n",
    "    classIDs = []\n",
    "    for output in layerOutputs:\n",
    "        for detection in output:\n",
    "            scores = detection[5:]\n",
    "            classID = np.argmax(scores)\n",
    "            confidence = scores[classID] # la probabilité avec laquelle cet objet à été détecté\n",
    "            if confidence > DEFAULT_CONFIANCE:\n",
    "                box = detection[0:4] * np.array([width, height, width, height])\n",
    "                (centerX, centerY, W, H) = box.astype(\"int\")\n",
    "                x = int(centerX - (W / 2))\n",
    "                y = int(centerY - (H / 2))\n",
    "                boxes.append([x, y, int(W), int(H)])\n",
    "                confidences.append(float(confidence))\n",
    "                classIDs.append(classID)\n",
    "    indexes = cv2.dnn.NMSBoxes(boxes, confidences, DEFAULT_CONFIANCE, THRESHOLD)\n",
    "    if len(indexes) > 0:\n",
    "        for i in indexes.flatten():\n",
    "            (x1,y1,w1,h1) = boxes[i]\n",
    "            text = \"{}: {:.4f}\".format(LABELS[classIDs[i]], confidences[i])\n",
    "            (cx1, cy1) = centre(x1,y1,w1,h1)\n",
    "            for j in indexes.flatten():\n",
    "                (x2,y2,w2,h2) = boxes[j]\n",
    "                if x1!=x2 and y1!=y2:\n",
    "                    (cx2, cy2) = centre(x2,y2,w2,h2)\n",
    "                    distance = euclidienne(cx1, cy1, cx2, cy2)           \n",
    "            if distance<N:\n",
    "                cv2.rectangle(image,(x1,y1),(x1+w1,y1+h1),(0,0,255),2)\n",
    "                cv2.putText(image, \"Attention!\", (x1, y1 - 15 ), cv2.FONT_HERSHEY_PLAIN, 2,(0,0,255),2)\n",
    "            else:\n",
    "                cv2.rectangle(image, (x1, y1), (x1 + w1, y1 + h1), (0,255,0), 2)\n",
    "                cv2.putText(image, \"personne\", (x1, y1 - 15 ), cv2.FONT_HERSHEY_PLAIN, 2, (0,255,0), 2)\n",
    "    cv2.imshow('Image', image)\n",
    "    if cv2.waitKey(1)==ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e24e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "del cv2\n",
    "del numpy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
